# ğŸ“¨ Celery + RabbitMQ + Redis (Dockerized Message Queue Demo)

A practical **DevOps mini-project** demonstrating how to build an **asynchronous task processing system** using **Celery**, **RabbitMQ**, and **Redis**, all running in **Docker containers**.

This setup helps you understand how distributed systems handle background jobs, message queues, and decoupled workloads in production environments.

---

## ğŸš€ Overview

This project demonstrates how backend services can:
- Queue background jobs instead of executing them synchronously.
- Decouple task submission from execution.
- Use **Celery** as a task queue framework.
- Use **RabbitMQ** as the **message broker**.
- Use **Redis** as the **result backend** to store task outcomes.

---

## ğŸ§  Architecture

```
Python App (Producer)
        â†“
   RabbitMQ (Broker)
        â†“
Celery Worker (Consumer)
        â†“
   Redis (Result Backend)
```

| Component | Role |
|------------|------|
| ğŸ‡ **RabbitMQ** | Acts as the **message broker** that queues and routes tasks. |
| âš™ï¸ **Celery Worker** | Processes background tasks asynchronously. |
| ğŸ§° **Redis** | Stores task results and states. |
| ğŸ **Python App** | Sends tasks to the queue and retrieves results. |

---

## ğŸ§± Project Structure

```
mq-demo/
â”‚
â”œâ”€â”€ docker-compose.yml        # Container orchestration
â””â”€â”€ app/
    â”œâ”€â”€ Dockerfile            # Python app container
    â”œâ”€â”€ requirements.txt      # Python dependencies
    â”œâ”€â”€ tasks.py              # Celery config & tasks
    â””â”€â”€ producer.py           # Example producer script
```

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Start the environment
```bash
docker compose up --build
```

This will start the following containers:

| Service | Description | Port |
|----------|--------------|------|
| `rabbitmq` | Message broker with web UI | **15672** |
| `redis` | Stores Celery task results | **6379** |
| `celery_worker` | Background task processor | â€” |
| `python_app` | Interactive container for sending tasks | â€” |

---

### 2ï¸âƒ£ Access RabbitMQ Dashboard

- URL â†’ [http://localhost:15672](http://localhost:15672)  
- Username â†’ `guest`  
- Password â†’ `guest`  

Go to **Queues â†’ celery** to see tasks being queued and consumed in real time.

---

### 3ï¸âƒ£ Run a Task Manually

Once all containers are up:
```bash
docker exec -it python_app bash
```

Then inside the container:
```bash
python producer.py
```

Expected output:
```
Sending task...
Task ID: 0fdcfdbf...
Waiting for result...
Result: 30
```

---

## ğŸ§  Understanding the Flow

| Step | Description |
|------|--------------|
| 1ï¸âƒ£ | The Python app sends a Celery task to RabbitMQ. |
| 2ï¸âƒ£ | RabbitMQ queues the task safely until a worker is ready. |
| 3ï¸âƒ£ | Celery worker consumes the task and executes it asynchronously. |
| 4ï¸âƒ£ | The worker stores the result in Redis. |
| 5ï¸âƒ£ | The app retrieves the result using the task ID. |

---

## ğŸ“Š Observability

### ğŸª¶ RabbitMQ Management UI
- Visualize queues, message rates, and acknowledgments.
- Monitor message flow between producers and consumers.

### ğŸ§± Redis (Check Task Results)
Inspect stored results directly from Redis:
```bash
docker exec -it redis redis-cli
keys *
get celery-task-meta-<task_id>
```

Youâ€™ll see something like:
```json
{"status": "SUCCESS", "result": 30, "traceback": null}
```

### ğŸ§¾ Celery Worker Logs
Tail the worker logs to view task execution in real time:
```bash
docker logs -f celery_worker
```

---

## ğŸ§° Tools & Technologies

- **Python 3.10**
- **Celery**
- **RabbitMQ** (Message Broker)
- **Redis** (Result Backend)
- **Docker & Docker Compose**

---

## ğŸ§¹ Cleanup

To stop and remove all containers, networks, and volumes:
```bash
docker compose down -v
```

---

## ğŸ§© Learning Objectives

âœ… Understand how message queues decouple services.  
âœ… Learn asynchronous task handling with Celery.  
âœ… Observe message flow between producers and consumers.  
âœ… Practice containerized orchestration with Docker Compose.  
âœ… Explore result storage using Redis.

---

## ğŸ’¡ Optional Enhancements

- Add a **Flask API** to trigger tasks via REST (`/run-task`, `/status/<id>`).  
- Integrate **Flower** for real-time Celery monitoring (`http://localhost:5555`).  
- Deploy to **Kubernetes** or **AWS ECS**.  
- Add **Prometheus + Grafana** for metrics and queue insights.  

---

## ğŸ§  Real-World Use Cases

- Asynchronous email or notification sending  
- Image/video processing pipelines  
- Report generation and scheduled jobs  
- ETL (Extract, Transform, Load) data workflows  
- Microservice communication patterns  

---

## ğŸ‘¨â€ğŸ’» Author

**Jayant Danech**  
Senior Cloud, DevOps & SysOps Engineer  

> A practical demonstration of asynchronous message queuing and distributed task processing using Celery, RabbitMQ, and Redis â€” for learning and DevOps practice.

